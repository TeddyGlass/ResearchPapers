# Axiomatic Attribution for Deep Networks
要約  
Deep learning の帰属問題において重要視されている２つの公理 1)感度 2)実装の不変性 の両者を満たした帰属方法「Integrated gradients」を著者らは開発した.  
<br>

# 背景
Deep learningモデルの予測根拠の可視化は医師がdeep learinginよる判定の根拠を理解する事例に役立ったこともあり, その重要性が一般的に認知されている.  

アトリビューション技術を設計する上での大きな課題は, それらを経験的に評価することが難しいということである. つまり**モデルの誤動作に起因するエラーとアトリビューション手法の誤動作に起因するエラーを区別することは困難**である. この欠点を補うために, 公理的なアプローチ **「Integrated Gradients」** をとる.  
<br>

# 2つの基盤となる公理
### 勾配
線形モデルの場合, 予測値をデバッグするためにモデル係数を検査する. そのため, ディープネットワークモデルの係数(勾配)を考えることは線形モデルのデバッグの発想をDeep learningモデルに転換する自然なアナロジーとなる. したがって, 勾配はDeep learningモデルの予測根拠解釈の合理的な出発点となる.

### 公理１　感度
帰属方法は、入力とベースラインが1つの特徴で異なっていても, 予測値が異なる場合には, その異なった特徴にゼロではない帰属を与えるべきである場合, Sensitivity(a)を満たすという. しかし, 勾配のみを用いた手法はSensitivityに違反する.以下に具体例を示す.  
1変数1ReLUネットワーク、$$f(x)=1 - ReLU(1-x)$$を考える.  
ベースラインが $x=0$ で、入力が $x=2$ だとする. 関数は0から1に変化するが, $f$は $x=1$ で平坦になるため, 勾配法では$x$に0が帰属する. 直感的に勾配法がSensitivityを破るのは, 予測関数が入力で平坦になり, 入力での関数値がベースラインでの値と異なるにもかかわらず, 勾配がゼロになることがあるからである. この現象は以前の研究でも報告されている（Shrikumar et al.2016）.

### 公理2　実装不変性
2つのネットワークが, 実装が大きく異なるにも関わらずすべての入力に対して出力が等しい場合, 機能的に等価であると考える. この場合帰属方法によって微分の連鎖律に影響を与える帰属手法を導入するべきでない.

# Integrated gradients
Integrated Gradientsは以下の式で定式化されます.  
$$Integrated \ Grads_i = (x_i - x^{\prime}_i)\times \int^1_0 \frac{{\partial}(F(x^{\prime}+{\alpha}(x-x^{\prime})))}{{\partial}x_i}　d{\alpha}$$ 


ここで, $x^{\prime}$はベースラインの入力, $x$は所望のサンプルの入力, $x_i$は入力$x$の$i$番目の次元の値, ${\alpha}$は摂動係数を指します. イメージとしては, ベースライン入力とサンプル入力を重ねたもの$x^{\prime}+{\alpha}(x-x^{\prime})$をモデルに投入し$i$番目のfeatureについて微分した際の局所勾配を算出し, この作業を${\alpha}=0$から${\alpha}=1$ の範囲で変化させ（サンプルの入力条件を変化させ）全て足し合わせる. これを, ベースラインの入力とサンプルの入力にどれくらいの差があるか？を示す $(x_i - x^{\prime}_i)$という情報に掛けることで, $x_i$の貢献度が計算されるということです.

GCNの場合, ベースラインを0と取ると上記の式は非常にシンプルなものとなります.
$$Integrated \ Grads_i = x_i\times \int^1_0 \frac{{\partial}F({\alpha}x)}{{\partial}x_i}　d{\alpha}$$  

![imgs_based_ig](/imgs/image_ig.png) 
<br>
![imgs_based_ig](/imgs/chem_ig.png) 